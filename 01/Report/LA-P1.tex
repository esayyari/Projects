\listfiles
\documentclass[twoside,12pt]{article}
\newcommand{\dataset}{{\cal D}}
\newcommand{\fracpartial}[2]{\frac{\partial #1}{\partial  #2}}
\usepackage{hyperref}
\usepackage{enumerate}
\usepackage[top=2in, bottom=1.5in, left=0.85in, right=0.5in]{geometry}
\usepackage[hyphenbreaks]{breakurl}
%\usepackage[pdfstartview=FitH,pdfstartpage=13,pdfpagemode=UseNone]{hyperref}
\usepackage{amsfonts}
\usepackage{graphicx} 
\usepackage[linesnumbered,ruled]{algorithm2e}
\usepackage{float}
\usepackage{amssymb,amsmath}
\usepackage{mdwlist }
\usepackage{color}
\usepackage[english]{babel}
\definecolor{darkblue}{rgb}{0.0,0.0,0.5}
\newtheorem{Dfn}{Definition}
\hypersetup{colorlinks,breaklinks,
            linkcolor=darkblue,urlcolor=darkblue,
            anchorcolor=darkblue,citecolor=darkblue}
\newcommand{\sign}{\text{sign}}
\begin{document}

\title{Learning Algorithms, Project 1}
\author{Arya Iranmehr, Mohsen Malmir, Erfan Sayyari}
\maketitle

\section{Introduction}
Logistic regression is one of the simplest linear classifiers. This model is linear, and thus inherently limited to problems that are linearly separable. Despite these limitations, We found logistic regression to be very powerful. For some problem in our research, when we used logistic regression for classification, we found it to be at least as good as SVM. For these reasons, we were very eager to dig into the details of implementing logistic regression. The result is a python class called {\it LogisticRegression}, which implements both regularized stochastic gradient descent and regularized L-BFGS for training. This class adapts the same interface used by {\it sklearn} classifiers, so it can be used in conjunction with {\it sklearn} feature extractors and other classifiers  in  pipelines. We hope to continue our work to the end of this course and implement different projects to provide an educational library of different classifiers.
\section{Design and Analysis of Algorithm}
In machine learning tasks, we usually want to decide about the state of the world, $y$, based on the observation $x$. To do this, we define a loss function to be minimized. And finally, we seek to find optimal decision function for our loss function. However, we may sometimes maximize the negative form of loss function to seek this goal. 

In this project, we are working with binary outcomes, $y\in\{{0,1}\}$, and observations ($x$) are real-valued vectors.  Furthermore, a logistic regression model for the conditional probability of y given x is assumed. Mathematically, we could write it as:
\begin{equation}
p(y|x;\alpha,\beta)=\frac{1}{1+exp-[\alpha+\sum_{j=1}^d\beta_jx_j}]
\end{equation}
where $x_j$ refers to jth feature of a d dimensional feature observation. 

So we want to learn a logistic regression model for the given training set, $\{(x_1,y_1),(x_2,y_2),...,(x_n,y_n)\}$. The training procedure is maximizing the log conditional likelihood for each training example:
\begin{equation}
LCL = \sum_{i=1}^n \log L(\theta;y_i | x_i).
\end{equation}

Moreover, we assume that $\log L(\theta;y_i|x_i)= \log p_i$ if $y_i=1$ and $\log L(\theta;y_i|x_i)=\log(1-p_i)$ if $y_i=0$, where $p_i = p(y=1|x_i;\theta).$
 
So the objective function is:
\begin{equation}
LCL=\sum_{i:y_i=1} \log p_i +\sum_{i:y_i=-1} \log (1-p_i).
\label{eq:LCL}
\end{equation}

To solve the maximization problem we have to compute the partial derivative of LCL with respect to $\beta_js$ and set it to zero. The partial derivative of objective function is:

\begin{equation}
\nabla_j=\frac{\partial}{\partial \beta_j}LCL=\sum_{i} (y_i-p_i)x_{ij}=0
\label{eq:pLCL}
\end{equation}
 where $x_{ij}$ is the value of jth feature of the ith observation (training example). So we will have a system of d equations and d unknowns which is extremely nonlinear. One of the ways to solve this system of equations is gradient descent. Thus in each step we have to update $\beta_j$ by the updating rule:
 \begin{equation}
 \beta_j=\beta_j+\lambda \frac{\partial}{\partial \beta_j}LCL.
 \end{equation}
 
 The major problem to solve this equation based on all features and training examples is time complexity. Evaluating this equation for all n training examples and all d features requires O(nd) time, and after each iteration $\beta_j$  can be adjusted a little. We can ease this problem by using stochastic methods. The idea is that at each iteration we use just one training example to update $\beta_j$. The mathematical equation for this solution is:

\begin{equation}
\tilde{\nabla}_j=\frac{\partial}{\partial \beta_j}LCL=\sum_{i \in \Omega} (y_i-p_i)x_{ij}
\label{eq:pLCL}
\end{equation}

Stochastic gradient descent is very useful in practice. if training data is sparse and for most of observations, $x_is$, the jth feature is zero ($x_{ij}=0$) and we could skip them to update $\beta_j$. So the time complexity of one epoch is O(nfd), where n is the total number of observations, d is the number of features, and f is the average number of nonzero features per example. In the following parts we will discuss each section separately. 

\subsection{Stochastic Gradient Descent}
The Stochastic Gradient Descent (SGD) method approximates objective function, simply by restricting the training set to a mini-batch, i.e. random sample. 
This makes a huge difference when the training set is large and can not be fitted into memory. We implemented SGD so that the size of mini-batch could be set\footnote{When size of mini-batch is very small, e.g. 1, the stochastic gradient become noisy leading to slow rate of convergence. On the other hand, we can choose to use larger mini-batch size to reduce the variance of the gradient, which makes gradient computation more costly.} to achieve desirable rate of convergence. We could write it mathematically as:

\begin{equation}
\beta_j=\beta_j+\lambda (y_i-p_i)x_{ij}
\end{equation}

Where $i$ is selected randomly. As described above, the complexity of main solution is O(nd), where n is the number of training examples and d is the number of features. While the time complexity of stochastic gradient descent is O(nfd), where f is the average number of nonzero feature values per observation. In fact we could skip most $x_js$ to update $\beta_j$. More specifically, for sparse data zero $x_j$ will not update $\beta_j$. So we could simply ignore them. At each epoch we may update all of the $\beta_js$ once, based on one data, or we can update one $\beta_j$ based on all of the training set first and then go to other parameters.

Presented stochastic gradient descent algorithm is unconstraint. The very important problem with unconstraint algorithm is that it may cause overfitting. To solve this problem we use regularization which will be discussed in following sections.
\subsection{LBFGS}
We used the {\it fmin\_l\_bfgs\_b} from { \it scipy.optimize} package, which implements the limited memory {\it BFGS} algorithm and is written by Ciyou Zhu, Richard Byrd, and Jorge Nocedal. This function takes as input the function to be minimized, which is in this case the negative of regularized conditional log-likelihood,
\begin{equation}
RLCL = \sum_{i=1}^N y_i \log(P_i) + (1-y_i)\log(1 - P_i) - \mu \|\beta\|_2^2
\end{equation}
where 
\begin{equation}
P_i = \frac{1}{1+e^{-\sum_{j=1}^d \beta_j x^i_j}}
\end{equation}
Is the probability of the $i$th sample $x^i$ belonging to class with label 1. 
\section{Design of Experiments}
\subsection{SGD}
\subsubsection{Initialization}
Since the problem is convex and the computational effort of each step is inexpensive, the initialization of SGD is not really important. So we simply initialized the parameter vector $\beta$ randomly by sampling from normal distribution. 

\subsubsection{Preprocessing}
Variety of the range of the features directly affects conditioning of the objective. Roughly speaking, if the variance of the features for data are significantly different the problem is ill-conditioned, and optimizing ill-conditioned problem with gradient-based methods leads to slow rates of convergence or even failure of convergence. To remedy this issue, we normalize all the features so that their mean and variance be 0 and 1, respectively.

\subsubsection{Grid Search}
We examined logistic regression (LR) and regularized logistic regression (RLR) in our experiments. The only difference is that in the prior, we know that $\mu=0$ which means that for LR we have one hyperparameter less to search. In order to find hyperparameters for LR ($\lambda_0$) and RLR ($\lambda_0,\mu$) we performed a coarse grid search on hyperparameter space, i.e. for $\lambda_0$ we used the range $(10^{-3}, 10^{-2}, 10^{-1}, 10^{0})$ and for $\mu$ we used the range $(10^{-3}, 10^{-2}, 10^{-1}, 10^{0}, 10^{1}, 10^{2} )$. For LR we have one hyperparameter and the grid search is one dimensional and for RLR the grid search is a 2-dimensional search over pairs of $\lambda_0 $ and $\mu$.

\subsubsection{Performance Measure}
While the logistic regression optimizes LCL, what matter is the accuracy of the algorithm on test examples. So, we should tune hyperparameters so that they have best performance on the unseen examples. One of the best way to estimate performance of hypeparameters on small datasets (such as Gender Detection) is cross validation. Cross-validation gives a plausible estimates the performance of the hyperparameters for the test phase. Therefore, in the grid search we considered 5-fold cross-validation for evaluating performance of hyperparameters and chose the hyperparameters which had the best cross-validation error on training set.

\subsection{L-BFGS}
For testing our implementation of training with L-BFGS, we used the gender detection dataset mentioned in the homework. This is a dataset with more than 800 features and less than 600 samples, meaning that there are many features that are redundant. The data files show that the input data for training and testing are both very sparse, this increases the potential for over-fitting in the case of logistic regression. However, as we mentioned before, regularization comes to our help to prevent over-fitting.
\subsubsection{Initialization}
The initialization of the parameters is limited to the weight vector $beta$, which is the decision boundary for logistic regression. In order to select this parameter, we used grid search over different values $[0.,1e-5,1e-4,1e-3,1e-2,1e-1,1.,10]$. One might say that the effect of initial value for $\beta$ might be alleviated by choosing the $\mu$, the weight decay parameter for regularization, so there is no need for the initial value. However, since we are only searching over a small  set of values for $\mu$, introducing the initial value for $\beta$ helps to search the problem space more widely.
\subsubsection{Preprocessing}
The only preprocessing we used was the scaling, which subtracts the mean vector of the data and scales each dimension to unit variance. This helps to keep the changes in different dimensions of $\beta$ in almost the same range.
\subsubsection{Grid Search}
For grid search, We used the class {\it sklearn.grid\_search.GridSearchCV}. The benefit of using this class is that it also implements cross validation, so we can perform grid search and model selection at the same time. This class accepts a classifier as input and the number of folds for cross validation, and performs K-fold cross validation to select the best model.
\subsubsection{Performance Measure}
For performance measurement, we can look at the conditional log-likelihood at different iterations. The function {\it fmin\_l\_bfgs\_b} allows us to call a callback function after each iteration. We used this function to measure the RLCL for both train and test sets. We also trained the logistic regression from python package {\it sklearn} and compared the our results with that.
\section{Results of Experiments}
\subsection{Regularized Logistic Regression}
\subsection{ Regularized L-BFGS}
For the first experiment, we set the regularization coefficient to 0, and allowed the initial weight value to be selected by grid search over $[0.,1e-5,1e-4,1e-3,1e-2,1e-1,1.,10]$. The optimal value of initial weight vector was selected to be 0.1 by grid search, meaning that the weight was initialized to a vector of Normal random numbers multiplied by $0.1$. Figure \ref{figNoReg} shows the evolution of LCL vs. iteration number for both train and test data. Note that for this case, We had to increase the parameter {\it factr} in {\it fmin\_l\_bfgs\_b} which is the threshold for normalized changes in the objective function.
\begin{figure}[h!]
\label{figNoReg}
\centering
\includegraphics[width=0.8\textwidth]{noreg.png}
\caption{LCL for train and test sets for the case of learning with no regularization, i.e. $\mu=0$.}
\end{figure}
In the second experiment, we omitted the search for initial value for the parameter vector $\beta$ and instead, used a constant value of 0.1. For the regularization parameter $\mu$, we performed grid search over the set of values $[.001,.01,.1,1,10,100,1000]$ with 3-fold cross validation over the train set. Figure {\ref{figNoBeta0}} plots the LCL and RLCL for both train and test sets.

\begin{figure}[h!]
\label{figNoBeta0}
\centering
\includegraphics[width=0.8\textwidth]{nobeta0.png}
\caption{LCL and RLCL for train and test sets for the case with no search over initial weight values.}
\end{figure}

For the third case, we used grid search over both initial value for $\beta$ and the regularization parameter $\mu$. The grid search used a 3-fold cross validation over the training data to pick the best model. Figure \ref{figBFGSComplete} shows the objective function for this run.

\begin{figure}[h!]
\label{figBFGSComplete}
\centering
\includegraphics[width=0.8\textwidth]{bfgs.png}
\caption{LCL and RLCL for train and test sets for the case with search over initial weight values and the regularization parameter.}
\end{figure}

Table \ref{tableBFGS} shows the result of recognition for train and test sets for L-BFGS learning for the three cases mentioned above.\\


\begin{table}[h!]\footnotesize
\label{tblbfgsrates}
  \caption{L-BFGS Recognition rate for different experiments}
\begin{center}
    \begin{tabular}{| c | c | c | }
    \hline
    \textbf{ Method} & \textbf{Training set recognition rate} & \textbf{Test set recognition} \\ \hline
    BFGS- no regularization & 0.9 & 0.91  \\ \hline
    BFGS- regularized with constant $\beta_0=0.1$ & 0.891 & 0.924  \\ \hline
    BFGS- regularized with search over $\beta_0$ & 0.894 & 0.916  \\ \hline
    sklearn.LogisticRegression & 0.905 & 0.916  \\ \hline
    
    \end{tabular}
\end{center}

\end{table}

\section{Findings and Lessons Learned}
\subsection{Numerical Issues and Preprocessing}
\subsection{Overfitting}
\subsection{Model Selection}
\subsection{Trade-off Between Mini-Batch size and Rate of Convergence}

\end{document}

